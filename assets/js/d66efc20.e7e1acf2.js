"use strict";(self.webpackChunktorque=self.webpackChunktorque||[]).push([[7200],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>h});var a=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},u=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(t),m=i,h=c["".concat(l,".").concat(m)]||c[m]||d[m]||r;return t?a.createElement(h,o(o({ref:n},u),{},{components:t})):a.createElement(h,o({ref:n},u))}));function h(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=t.length,o=new Array(r);o[0]=m;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s[c]="string"==typeof e?e:i,o[1]=s;for(var p=2;p<r;p++)o[p]=t[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},7521:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>p});var a=t(7462),i=(t(7294),t(3905));const r={sidebar_position:1,title:"Torque Workflows"},o=void 0,s={unversionedId:"workflows/workflows-overview",id:"workflows/workflows-overview",title:"Torque Workflows",description:"Workflow",source:"@site/docs/workflows/workflows-overview.md",sourceDirName:"workflows",slug:"/workflows/workflows-overview",permalink:"/workflows/workflows-overview",editUrl:"https://github.com/QualiTorque/torque-docs/tree/master/docs/workflows/workflows-overview.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"Torque Workflows"},sidebar:"torqueSidebar",previous:{title:"The Environment YAML",permalink:"/environment-as-code/environment-as-code-yaml"},next:{title:"Users, Groups, Roles and Permissions",permalink:"/governance/roles-and-permissions"}},l={},p=[{value:"Workflow",id:"workflow",level:2},{value:"Bindings",id:"bindings",level:3},{value:"Environment <code>contract</code> Object",id:"environment-contract-object",level:3},{value:"Triggers",id:"triggers",level:3},{value:"YAML",id:"yaml",level:3},{value:"Torque <code>built-in</code> Workflows",id:"torque-built-in-workflows",level:2},{value:"<code>built-in</code> workflows",id:"built-in-workflows",level:3},{value:"Use-Cases and Examples",id:"use-cases-and-examples",level:2},{value:"Example 1: Extract VM power state",id:"example-1-extract-vm-power-state",level:3},{value:"Example 2: Attach an EBS volume to an EC2 instance",id:"example-2-attach-an-ebs-volume-to-an-ec2-instance",level:3},{value:"Example 3: Detach an EBS volume from an EC2 instance",id:"example-3-detach-an-ebs-volume-from-an-ec2-instance",level:3}],u={toc:p},c="wrapper";function d(e){let{components:n,...t}=e;return(0,i.kt)(c,(0,a.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"workflow"},"Workflow"),(0,i.kt)("p",null,"Workflows are a powerful way to automate and orchestrate complex processes. They allow you to define a series of actions and steps that are executed in a specific order. Workflows can be triggered by events or scheduled to run at specific times."),(0,i.kt)("p",null,"Workflow discovery is done in the same way of Blueprints. The yaml needs to be under the ",(0,i.kt)("inlineCode",{parentName:"p"},"blueprints/")," directory in the repository."),(0,i.kt)("p",null,"The Workflow YAML standard is similar to the Blueprint standard. The only addition to the Workflow specification is the the ",(0,i.kt)("inlineCode",{parentName:"p"},"workflow")," block."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: This Workflow will ...\n\n// highlight-start\nworkflow:\n  scope: env\n// highlight-end\n\ngrains: ...\n")),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"scope")," field in a Torque workflow determines where the workflow is available. There are two possible values for the ",(0,i.kt)("inlineCode",{parentName:"p"},"scope")," field:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"env"),": Workflows with this scope are available at the environment level. This means that they can be triggered and executed for the entire environment. These workflows can be used to automate and orchestrate processes that involve multiple resources within the environment.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},(0,i.kt)("inlineCode",{parentName:"p"},"env_resource"),": Workflows with this scope are available at the resource level. The availability of these workflows is based on the resource type defined in the ",(0,i.kt)("inlineCode",{parentName:"p"},"label-selector")," field. Only resources that match the specified resource type will have access to these workflows. This allows for more granular control and customization of workflows based on specific resource types.\nFor example:"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml",metastring:"showLineNumbers",showLineNumbers:!0},"spec_version: 2\ndescription: This Resource Workflow will ...\n\n// highlight-start\nworkflow:\n  scope: env_resource\n  label-selector: aws_instance\n// highlight-end\n\n\ngrains: ...\n")),(0,i.kt)("p",null,"By specifying the appropriate scope for your workflows, you can ensure that they are available and applicable to the desired level of your infrastructure. Whether you need to automate processes at the environment level or target specific resources, Torque workflows provide the flexibility to meet your automation needs."),(0,i.kt)("h3",{id:"bindings"},"Bindings"),(0,i.kt)("p",null,"In a workflow, you can define bindings to access environment and resource information. Bindings are automatic variables that provide context to the workflow. The available bindings depend on the scope of the workflow."),(0,i.kt)("p",null,"For workflows with scope ",(0,i.kt)("inlineCode",{parentName:"p"},"env"),", the following automatic variables are available:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"bindings.environment_id"))),(0,i.kt)("p",null,"For workflows with scope ",(0,i.kt)("inlineCode",{parentName:"p"},"env_resource"),", the following automatic variables are available:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"bindings.environment_id")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"bindings.grain_path")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"bindings.resource_id"))),(0,i.kt)("p",null,"The binding variables will provide the relevant context to access the relevant resource introspection data in the ",(0,i.kt)("inlineCode",{parentName:"p"},"contract")," object available in the workflow."),(0,i.kt)("h3",{id:"environment-contract-object"},"Environment ",(0,i.kt)("inlineCode",{parentName:"h3"},"contract")," Object"),(0,i.kt)("p",null,"When a workflow is executed with a specific scope, the environment ",(0,i.kt)("strong",{parentName:"p"},"context")," JSON object is provided in a file called ",(0,i.kt)("inlineCode",{parentName:"p"},"contract.json"),". This file is accessible from the Runner and contains information about the environment, such as its ID, name, owner email, inputs and all grains introspection data."),(0,i.kt)("p",null,"Here is an example of a ",(0,i.kt)("inlineCode",{parentName:"p"},"contract.json")," file:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "id": "kuzxqUlGSM4C",\n  "name": "EC2",\n  "owner_email": "dev@quali.com",\n  "last_used": "2023-10-07T11:57:18.6865654Z",\n  "inputs": [\n    {\n      "name": "instance_name",\n      "type": "string",\n      "value": "EC2",\n      "sensitive": false,\n      "description": "Name for the EC2 instance"\n    },\n    {\n      "name": "aws_region",\n      "type": "string",\n      "value": "eu-west-1",\n      "sensitive": false,\n      "description": "AWS region to create resources in"\n    },\n    {\n      "name": "instance_ami",\n      "type": "string",\n      "value": "ami-016587dea5af03adb",\n      "sensitive": false,\n      "description": "AMI ID for the EC2 instance"\n    },\n    {\n      "name": "instance_type",\n      "type": "string",\n      "value": "t2.micro",\n      "sensitive": false,\n      "description": "Instance type for the EC2 instance"\n    },\n    {\n      "name": "key_pair_name",\n      "type": "string",\n      "value": "key-pair",\n      "sensitive": false,\n      "description": "Name of the key pair"\n    },\n    {\n      "name": "agent",\n      "type": "agent",\n      "value": "cloud-agent",\n      "sensitive": false,\n      "description": null\n    }\n  ],\n  "grains": {\n    "ec2": {\n      "kind": "terraform",\n      "path": "ec2",\n      "outputs": {\n        "instance_availability_zone": "eu-west-1c",\n        "instance_id": "i-044264d8ee1c50f3d",\n        "instance_private_ip": "172.31.28.188",\n        "instance_public_ip": "18.203.238.11",\n        "instance_subnet_id": "subnet-0c1abbaed3cdbdb66"\n      }\n    },\n    "root_blueprint": {\n      "kind": "blueprint",\n      "path": "root_blueprint",\n      "outputs": {\n        "ec2_instance_availability_zone": "eu-west-1c",\n        "ec2_instance_id": "i-044264d8ee1c50f3d",\n        "ec2_instance_private_ip": "172.31.28.188",\n        "ec2_instance_public_ip": "18.203.238.11",\n        "ec2_instance_subnet_id": "subnet-0c1abbaed3cdbdb66",\n        "ec2_instance_vpc_id": ""\n      }\n    }\n  },\n  "resources": [\n    {\n      "grain_path": "ec2",\n      "resource_name": "my_ec2_instance",\n      "resource_type": "aws_instance",\n      "identifier": "aws_instance.my_ec2_instance",\n      "attributes": {\n        "id": "i-044264d8ee1c50f3d",\n        "ami": "ami-016587dea5af03adb",\n        "arn": "arn:aws:ec2:eu-west-1:<accout-id>:instance/i-044264d8ee1c50f3d",\n        "tags": "..",\n        "host_id": "",\n        "tenancy": "default",\n        "key_name": "key-pair",\n        "tags_all": "..",\n        "timeouts": "",\n        "public_ip": "18.203.238.11",\n        "subnet_id": "subnet-0c1abbaed3cdbdb66",\n        "user_data": "",\n        "monitoring": "False",\n        "private_ip": "172.31.28.188",\n        "public_dns": "ec2-18-203-238-11.eu-west-1.compute.amazonaws.com",\n        "cpu_options": "[\\n  {\\n    \\"amd_sev_snp\\": \\"\\",\\n    \\"core_count\\": 1,\\n    \\"threads_per_core\\": 1\\n  }\\n]",\n        "hibernation": "False",\n        "outpost_arn": "",\n        "private_dns": "ip-172-31-28-188.eu-west-1.compute.internal",\n        "volume_tags": "",\n        "ebs_optimized": "False",\n        "instance_type": "t2.micro",\n        "******_data": "",\n        "cpu_core_count": "1",\n        "instance_state": "running",\n        "ipv6_addresses": "[]",\n        "enclave_options": "[\\n  {\\n    \\"enabled\\": false\\n  }\\n]",\n        "launch_template": "[]",\n        "placement_group": "",\n        "security_groups": "[\\n  \\"default\\"\\n]",\n        "disable_api_stop": "False",\n        "ebs_block_device": "[]",\n        "metadata_options": "[\\n  {\\n    \\"http_endpoint\\": \\"enabled\\",\\n    \\"http_protocol_ipv6\\": \\"disabled\\",\\n    \\"http_put_response_hop_limit\\": 1,\\n    \\"http_tokens\\": \\"optional\\",\\n    \\"instance_metadata_tags\\": \\"disabled\\"\\n  }\\n]",\n        "user_data_base64": "",\n        "availability_zone": "eu-west-1c",\n        "get_******_data": "False",\n        "network_interface": "[]",\n        "root_block_device": "[\\n  {\\n    \\"delete_on_termination\\": true,\\n    \\"device_name\\": \\"/dev/sda1\\",\\n    \\"encrypted\\": false,\\n    \\"iops\\": 100,\\n    \\"kms_key_id\\": \\"\\",\\n    \\"tags\\": {},\\n    \\"tags_all\\": {},\\n    \\"throughput\\": 0,\\n    \\"volume_id\\": \\"vol-00160f2bba38f64ea\\",\\n    \\"volume_size\\": 8,\\n    \\"volume_type\\": \\"gp2\\"\\n  }\\n]",\n        "source_dest_check": "True",\n        "instance_lifecycle": "",\n        "ipv6_address_count": "0",\n        "maintenance_options": "[\\n  {\\n    \\"auto_recovery\\": \\"default\\"\\n  }\\n]",\n        "cpu_threads_per_core": "1",\n        "credit_specification": "[\\n  {\\n    \\"cpu_credits\\": \\"standard\\"\\n  }\\n]",\n        "iam_instance_profile": "",\n        "secondary_private_ips": "[]",\n        "ephemeral_block_device": "[]",\n        "vpc_security_group_ids": "[\\n  \\"sg-085399a72b47e21e3\\"\\n]",\n        "disable_api_termination": "False",\n        "host_resource_group_arn": "",\n        "instance_market_options": "[]",\n        "private_dns_name_options": "[\\n  {\\n    \\"enable_resource_name_dns_a_record\\": false,\\n    \\"enable_resource_name_dns_aaaa_record\\": false,\\n    \\"hostname_type\\": \\"ip-name\\"\\n  }\\n]",\n        "spot_instance_request_id": "",\n        "placement_partition_number": "0",\n        "associate_public_ip_address": "True",\n        "user_data_replace_on_change": "False",\n        "primary_network_interface_id": "eni-03e8445441f4ddb2e",\n        "capacity_reservation_specification": "[\\n  {\\n    \\"capacity_reservation_preference\\": \\"open\\",\\n    \\"capacity_reservation_target\\": []\\n  }\\n]",\n        "instance_initiated_shutdown_behavior": "stop"\n      }\n    }\n  ]\n}\n')),(0,i.kt)("h3",{id:"triggers"},"Triggers"),(0,i.kt)("p",null,"Workflows can be triggered by various types of events or schedules:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("inlineCode",{parentName:"li"},"cron"),": Schedules based on cron expressions.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"overridable"),": Optional field to allow end-users to override the cron"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("inlineCode",{parentName:"li"},"manual"),": Manually triggered workflows, optionally restricted to specific user groups.",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"groups"),": Optional field to allow only users in the specified groups to run the workflow"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("inlineCode",{parentName:"li"},"env-event"),": Environment events can be events such as drift detected, updates detected, approval requests, and more. The events include:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Drift Detected")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Updates Detected")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Approval Request Approved")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Approval Request Denied")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Approval Request Cancelled")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Ended")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Launched")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Active With Error")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Ending Failed")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Force Ended")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Extended")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Collaborator Added")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"Environment Idle"))))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: ...\n\nworkflow:\n  scope: env\n\n// highlight-start\n  triggers:\n    - type: env-event\n      events:\n        - 'Approval Request Approved'\n        - 'Approval Request Cancelled'\n\n    - type: cron \n      cron: '0 22 * * *' # every day at 22:00\n      overridable: true # Allow end-users to override the cron\n\n    - type: manual \n      groups: # Optional, allow only users in the \"Admin\" group to run the workflow\n        - 'Admins' \n// highlight-end\n   \ninputs: ...\noutputs: ...\ngrains: ...\n")),(0,i.kt)("h3",{id:"yaml"},"YAML"),(0,i.kt)("p",null,"Simple example running shell script in a Workflow"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: Workflow with shell grains\n\nworkflow:\n  scope: env_resource\n  label-selector: azurerm_linux_virtual_machine\n  \ninputs:\n  input1:\n    type: string\n    default: 'in1'\n  input2:\n    type: string\n  agent:\n    type: agent\n\noutputs:\n  resource_state:\n    value: '{{ .grains.helper.activities.deploy.commands.print.outputs.state_tr }}'  \n  input1:\n    value: '{{ .inputs.input1 }}'  \n  \ngrains:\n  helper:\n    kind: shell\n    spec:\n      agent:\n          name: '{{ .inputs.agent }}'\n      files:\n        - source: scripts\n          path: scripts/print-resource-2.sh\n      activities:\n        deploy:\n          commands:\n            - name: print\n              command:  'source print-resource-2.sh {{ .bindings.resource_id }} {{ .bindings.grain_path }}'\n              outputs:\n                - state_tr\n\n  job2:\n    kind: shell\n    depends-on: helper\n    spec:\n      agent:\n        name: '{{ .inputs.agent }}'\n      activities:\n        deploy:\n          commands:\n            - name: print                  \n              command:  'echo \"{{ .grains.helper.activities.deploy.commands.print.outputs.state_tr }}\"'\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Shell script:")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'resource_id=$1\ngrain_path=$2\ncontract_path=$CONTRACT_FILE_PATH\n\n# will print the attribute "power_state" of the resource\nstate=$(jq --arg ResourceId "$resource_id" --arg GrainPath "$grain_path" \'.resources[] | select(.identifier == $ResourceId and .grain_path == $GrainPath) | .attributes | .power_state\' $contract_path)\n\nexport state_tr=`echo -n $state | tr -d \'"\'`\n\necho ""\necho "extracted values:"\necho "------------------"\necho "state_tr: $state_tr"\necho "------------------"\necho ""\n\ncat $CONTRACT_FILE_PATH\necho $state_tr\nexport $state_tr\n')),(0,i.kt)("h2",{id:"torque-built-in-workflows"},"Torque ",(0,i.kt)("inlineCode",{parentName:"h2"},"built-in")," Workflows"),(0,i.kt)("h3",{id:"built-in-workflows"},(0,i.kt)("inlineCode",{parentName:"h3"},"built-in")," workflows"),(0,i.kt)("p",null,"Torque provides some out-of-the-box workflows for you to use."),(0,i.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"All the built-in workflows are ",(0,i.kt)("inlineCode",{parentName:"p"},"Ansible")," based and available here: ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/QualiTorque/torque-actions"},"https://github.com/QualiTorque/torque-actions")))),(0,i.kt)("p",null,"In order to use the built-in workflows, a ",(0,i.kt)("inlineCode",{parentName:"p"},"built-in")," field is required and under source.path you need to point to the relevant action. E.g.:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"      built-in: true\n      source:\n        path: https://github.com/QualiTorque/torque-actions.git//resource/<action>.yaml\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"The list of the available actions:")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-power-on-ec2-tf"),": This workflow is used to power on an EC2 instance in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-power-off-ec2-tf"),": This workflow is used to power off an EC2 instance in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-restart-ec2-tf"),": This workflow is used to restart an EC2 instance in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-power-on-vm-tf"),": This workflow is used to power on a virtual machine in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-power-off-vm-tf"),": This workflow is used to power off a virtual machine in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-restart-vm-tf"),": This workflow is used to restart a virtual machine in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"netapp-cvo-azure-power-on-vm-tf"),": This workflow is used to power on a NetApp Cloud Volumes ONTAP virtual machine in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"netapp-cvo-azure-deallocate-vm-tf"),": This workflow is used to deallocate a NetApp Cloud Volumes ONTAP virtual machine in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"netapp-cvo-azure-restart-vm-tf"),": This workflow is used to restart a NetApp Cloud Volumes ONTAP virtual machine in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-temp-stop-rds-tf"),": This workflow is used to temporarily stop an RDS instance in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-delete-rds-tf"),": This workflow is used to delete an RDS instance in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-delete-mariadb-tf"),": This workflow is used to delete a MariaDB server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-delete-mysql-tf"),": This workflow is used to delete a MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-delete-postgresql-tf"),": This workflow is used to delete a PostgreSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-delete-flexible-mysql-tf"),": This workflow is used to delete a flexible MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-delete-flexible-postgresql-tf"),": This workflow is used to delete a flexible PostgreSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-delete-mssql-tf"),": This workflow is used to delete an MSSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-stop-mysql-server-tf"),": This workflow is used to stop a MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-start-mysql-server-tf"),": This workflow is used to start a MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-stop-mariadb-server-tf"),": This workflow is used to stop a MariaDB server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-start-mariadb-server-tf"),": This workflow is used to start a MariaDB server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-stop-flexible-postgresql-server-tf"),": This workflow is used to stop a flexible PostgreSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-start-flexible-postgresql-server-tf"),": This workflow is used to start a flexible PostgreSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-stop-flexible-mysql-server-tf"),": This workflow is used to stop a flexible MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-start-flexible-mysql-server-tf"),": This workflow is used to start a flexible MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-restart-mariadb-server-tf"),": This workflow is used to restart a MariaDB server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-restart-mysql-server-tf"),": This workflow is used to restart a MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-restart-flexible-mysql-server-tf"),": This workflow is used to restart a flexible MySQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-restart-flexible-postgresql-server-tf"),": This workflow is used to restart a flexible PostgreSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-restart-postgresql-server-tf"),": This workflow is used to restart a PostgreSQL server in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-start-rds-tf"),": This workflow is used to start an RDS instance in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-power-on-ec2-cfn"),": This workflow is used to power on an EC2 instance in AWS that was provisioned using CloudFormation.."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-power-off-ec2-cfn"),": This workflow is used to power off an EC2 instance in AWS that was provisioned using CloudFormation.."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-restart-ec2-cfn"),": This workflow is used to restart an EC2 instance in AWS that was provisioned using CloudFormation.."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-temp-stop-rds-cfn"),": This workflow is used to temporarily stop an RDS instance in AWS that was provisioned using CloudFormation.."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-start-rds-cfn"),": This workflow is used to start an RDS instance in AWS that was provisioned using CloudFormation.."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-pause-aks-tf"),": This workflow is used to pause an AKS cluster in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"azure-resume-aks-tf"),": This workflow is used to resume an AKS cluster in Azure that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-pause-eks-tf"),": This workflow is used to pause an EKS cluster in AWS that was provisioned using Terraform."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"aws-resume-eks-tf"),": This workflow is used to resume an EKS cluster in AWS that was provisioned using Terraform.")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Example of ",(0,i.kt)("inlineCode",{parentName:"strong"},"built-in")," workflow:")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: manual blueprint for delete AWS RDS resource action\n\nworkflow:\n  scope: env\n  label-selector: eks_cluster\n  triggers:\n    - type: manual\n\ninputs:\n  agent:\n    type: agent\n    default: cloud-agent\n\ngrains:\n  pause_eks:\n    kind: ansible\n    spec:\n// highlight-start\n      built-in: true\n      source:\n        path: https://github.com/QualiTorque/torque-actions.git//resource/aws-pause-eks-tf.yaml\n// highlight-end\n      agent:\n        name: '{{ .inputs.agent }}'\n")),(0,i.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("ul",{parentName:"div"},(0,i.kt)("li",{parentName:"ul"},"Only one grain with ",(0,i.kt)("em",{parentName:"li"},"built-in")," action may be present in workflow blueprint"),(0,i.kt)("li",{parentName:"ul"},"One action will be ran per one introspection resource. ")))),(0,i.kt)("h2",{id:"use-cases-and-examples"},"Use-Cases and Examples"),(0,i.kt)("p",null,"This example demonstrates a simple workflow that includes shell grains with dependencies."),(0,i.kt)("h3",{id:"example-1-extract-vm-power-state"},"Example 1: Extract VM power state"),(0,i.kt)("p",null,"Simple Workflow example to extract Azure VM power state"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Gather information about the current power state of Azure VM resources. "),(0,i.kt)("li",{parentName:"ul"},"This information can be useful for various purposes, such as monitoring, troubleshooting, or automation tasks. By extracting the power state, you can determine whether a VM is running, stopped, or in any other power state, and use this information to make informed decisions or trigger further actions based on the VM's power state. "),(0,i.kt)("li",{parentName:"ul"},"This workflow provides a convenient way to extract the power state of Azure VM resources and make it available as an output for further processing or integration with other systems.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: Workflow with extract Azure VM power state\n\nworkflow:\n  scope: env_resource\n  label-selector: azurerm_linux_virtual_machine # will be available for all azure VM resources type\n  \ninputs:\n  agent:\n    type: agent\n    default: azure-agent\n\noutputs:\n  resource_state:\n    value: '{{ .grains.power-state.activities.deploy.commands.print.outputs.state }}'  \n  \ngrains:\n  power-state:\n    kind: shell\n    spec:\n      agent:\n          name: '{{ .inputs.agent }}'\n      files:\n        - source: scripts\n          path: scripts/print-resource-2.sh\n      activities:\n        deploy:\n          commands:\n            - name: print\n              command:  'source print-resource-2.sh {{ .bindings.resource_id }} {{ .bindings.grain_path }}'\n              outputs:\n                - state\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Shell script:")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'resource_id=$1\ngrain_path=$2\ncontract_path=$CONTRACT_FILE_PATH\n\n# will print the attribute "power_state" of the resource\nstate_str=$(jq --arg ResourceId "$resource_id" --arg GrainPath "$grain_path" \'.resources[] | select(.identifier == $ResourceId and .grain_path == $GrainPath) | .attributes | .power_state\' $contract_path)\n\nexport state=`echo -n $state_tr | tr -d \'"\'`\n\necho ""\necho "extracted values:"\necho "------------------"\necho "state: $state"\necho "------------------"\necho ""\n\ncat $CONTRACT_FILE_PATH\necho $state_tr\nexport $state_tr\n')),(0,i.kt)("h3",{id:"example-2-attach-an-ebs-volume-to-an-ec2-instance"},"Example 2: Attach an EBS volume to an EC2 instance"),(0,i.kt)("p",null,"Workflow that attach an EBS volume to an EC2 instance using Ansible grain"),(0,i.kt)("p",null,'Running the "Attach volume to EC2" workflow enables you to enhance the storage capabilities of your EC2 instances, improve data management, and optimize performance, ultimately leading to a more efficient and reliable infrastructure. It provides several benefits:'),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Scalability"),": By attaching additional EBS volumes to your EC2 instances, you can increase the storage capacity available to your applications. This allows you to handle larger amounts of data and accommodate growing workloads."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Flexibility"),": Attaching EBS volumes gives you the flexibility to store different types of data separately. For example, you can attach a volume specifically for database storage or one for log files. This separation improves organization and makes it easier to manage and troubleshoot your resources."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Data Persistence"),": EBS volumes are persistent storage devices, meaning that the data stored on them remains intact even if the EC2 instance is stopped or terminated. This ensures that your valuable data is preserved and can be accessed whenever needed."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"High Availability"),": By attaching multiple EBS volumes to your EC2 instances, you can distribute your data across different volumes. This improves fault tolerance and ensures that your applications remain available even if one volume fails."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Performance Optimization"),": EBS volumes offer different performance characteristics based on their volume types. By attaching volumes with the appropriate performance characteristics, you can optimize the storage performance of your EC2 instances and improve the overall responsiveness of your applications.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: Attach an EBS volume to an EC2 instance using Ansible grain\n\nworkflow:\n  scope: env_resource\n  label-selector: aws_instance # will be available for all aws ec2 resources type\n\ninputs:\n  ebs_volume_size:\n    type: string\n    default: 1\n  device_name:\n    type: string\n    default: /dev/sdf\n  volume_type:\n    type: string\n    default: gp3\n\noutputs:\n  volume_id:\n    value: '{{ .grains.attach_volume.outputs.volume_id }}'\n    quick: true\n  volume_name:\n    value: '{{ .grains.attach_volume.outputs.volume_name }}'\n    quick: true\n  volume_operation_data:\n    value: '{{ .grains.attach_volume.outputs.volume_operation_data }}'\n    quick: true\n\ngrains:\n  helper:\n    kind: shell\n    spec:\n      agent:\n        name: cloud-agent\n      files:\n        - source: blueprints\n          path: blueprints/workflows/scripts/attach-detach-helper.sh\n      activities:\n        deploy:\n          commands:\n            - name: get-outputs\n              command:  'source attach-detach-helper.sh {{ .bindings.resource_id }} {{ .bindings.grain_path }}'\n              outputs:\n                - id\n                - region\n                - availability_zone\n\n  attach_volume:\n    depends-on: helper\n    kind: ansible\n    spec:\n      source:\n        store: ansible\n        path: attach_volume/attach_volume.yml\n      agent:\n        name: cloud-agent\n      inputs:\n      - ec2_instance_id: '{{ .grains.helper.activities.deploy.commands.get-outputs.outputs.id }}'\n      - aws_region: '{{ .grains.helper.activities.deploy.commands.get-outputs.outputs.region }}'\n      - availability_zone: '{{ .grains.helper.activities.deploy.commands.get-outputs.outputs.availability_zone }}'\n      - ebs_volume_size: '{{ .inputs.ebs_volume_size }}'\n      - device_name: '{{ .inputs.device_name }}'\n      - volume_type: '{{ .inputs.volume_type }}'\n      - env_id: '{{ envId }}'\n      - volume_name: 'ebs-volume-{{ envId }}'\n      env-vars: []\n      outputs:\n      - volume_operation_data\n      - volume_name\n      - volume_id\n\n      inventory-file:\n        localhost:\n          hosts:\n            127.0.0.1:\n              ansible_connection: local\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Ansible playbook:")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"---\n- hosts: localhost\n  connection: local\n  gather_facts: false\n\n  tasks:\n    - name: Install boto3 python package\n      pip:\n        name: boto3\n        \n    # Create new volume using SSD storage\n    - name: Create and attach new EBS volume\n      amazon.aws.ec2_vol:\n        instance: \"{{ ec2_instance_id | replace('\\n', '') }}\"\n        region: \"{{ aws_region | replace('\\n', '') }}\"\n        zone: \"{{ availability_zone | replace('\\n', '') }}\"\n        volume_size: \"{{ ebs_volume_size | replace('\\n', '') }}\"\n        device_name: \"{{ device_name | replace('\\n', '') }}\"\n        volume_type: \"{{ volume_type | replace('\\n', '') }}\"\n        delete_on_termination: true # The volume will be deleted upon instance termination.\n      register: attached_volume\n\n    - name: Ensure tags are present on a resource\n      amazon.aws.ec2_tag:\n        region: \"{{ aws_region | replace('\\n', '') }}\"\n        resource: \"{{ attached_volume.volume_id }}\"\n        state: present\n        tags:\n          Name: \"{{ volume_name | replace('\\n', '') }}\"\n          env: prod\n    \n    - name: Export outputs\n      torque.collections.export_torque_outputs:\n        outputs:\n          volume_name: \"{{ volume_name | replace('\\n', '') }}\"\n          volume_id: \"{{ attached_volume.volume_id }}\"\n          volume_operation_data: \"{{ attached_volume }}\"\n")),(0,i.kt)("h3",{id:"example-3-detach-an-ebs-volume-from-an-ec2-instance"},"Example 3: Detach an EBS volume from an EC2 instance"),(0,i.kt)("p",null,"Workflow that detach an EBS volume from an EC2 instance using Ansible grain"),(0,i.kt)("p",null,'Running the "Detach an EBS volume from an EC2 instance" workflow helps you optimize costs, manage resources efficiently, enhance data security, and perform maintenance and troubleshooting tasks effectively. It provides several benefits:'),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Cost Optimization"),": By detaching unused or unnecessary EBS volumes from EC2 instances, you can reduce storage costs. Detaching volumes that are no longer needed helps to eliminate unnecessary charges and optimize your cloud infrastructure expenses."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Resource Management"),": Detaching EBS volumes allows you to efficiently manage your storage resources. By detaching volumes that are not actively being used, you can free up storage capacity and allocate it to other instances or applications that require it. This helps to ensure that your resources are utilized effectively and avoids unnecessary resource wastage."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Data Security"),": Detaching EBS volumes from EC2 instances can enhance data security. By detaching volumes before terminating or decommissioning instances, you can ensure that sensitive data stored on those volumes is not accessible to unauthorized users. This helps to protect your data and maintain compliance with security and privacy regulations."),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("strong",{parentName:"li"},"Maintenance and Troubleshooting"),": Detaching EBS volumes can be useful for maintenance and troubleshooting purposes. By detaching volumes, you can perform maintenance tasks such as resizing, snapshotting, or modifying volume attributes without impacting the running instances. It also allows you to troubleshoot issues related to specific volumes without affecting the overall availability of your EC2 instances.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"spec_version: 2\ndescription: Detach an EBS volume from an EC2 instance\n\nworkflow:\n  scope: env_resource\n  label-selector: aws_instance\n\ninputs:\n  volume_id:\n    type: string\n\ngrains:\n  helper:\n    kind: shell\n    spec:\n      agent:\n        name: cloud-agent\n      files:\n        - source: blueprints\n          path: blueprints/workflows/scripts/attach-detach-helper.sh\n      activities:\n        deploy:\n          commands:\n            - name: get-outputs\n              command:  'source attach-detach-helper.sh {{ .bindings.resource_id }} {{ .bindings.grain_path }}'\n              outputs:\n                - id\n                - region\n                - availability_zone\n\n  detach_volume:\n    depends-on: helper\n    kind: ansible\n    spec:\n      source:\n        store: ansible\n        path: detach_volume/detach_volume.yml\n      agent:\n        name: cloud-agent\n      inputs:\n      - aws_region: '{{ .grains.helper.activities.deploy.commands.get-outputs.outputs.region }}'\n      - volume_id: '{{ .inputs.volume_id }}'\n      env-vars: []\n      inventory-file:\n        localhost:\n          hosts:\n            127.0.0.1:\n              ansible_connection: local\n\n")),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Ansible playbook:")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},"---\n- hosts: localhost\n  connection: local\n  gather_facts: false\n\n  tasks:\n    - name: Install boto3 python package\n      pip:\n        name: boto3\n    # Detach a volume\n    - name: Detach a volume\n      amazon.aws.ec2_vol:\n        region: \"{{ aws_region | replace('\\n', '') }}\"\n        id: \"{{ volume_id | replace('\\n', '') }}\"\n        instance: None\n")))}d.isMDXComponent=!0}}]);